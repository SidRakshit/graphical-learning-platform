# backend/sagemaker_service.py

import os
import json
import boto3
from botocore.exceptions import ClientError

# --- Configuration ---
# These are read from the environment variables set by Terraform in your Lambda function
SAGEMAKER_ENDPOINT_NAME = os.environ.get("SAGEMAKER_ENDPOINT_NAME")
AWS_REGION_NAME = os.environ.get(
    "AWS_REGION", "us-east-1"
)  # Default to us-east-1 if not set

# Initialize the Boto3 client once to be reused
# Boto3 clients are generally thread-safe
try:
    sagemaker_runtime = boto3.client("sagemaker-runtime", region_name=AWS_REGION_NAME)
except Exception as e:
    print(f"FATAL: Could not create sagemaker-runtime client: {e}")
    sagemaker_runtime = None


class SageMakerService:
    """A service to interact with the AWS SageMaker endpoint."""

    def generate_text(self, prompt: str) -> str:
        """
        Invokes the Sage-Maker endpoint to generate a text response from a prompt.

        Args:
            prompt: The user prompt to send to the model.

        Returns:
            The text generated by the model.

        Raises:
            ValueError: If the service is not configured properly.
            Exception: If the endpoint invocation fails.
        """
        if not sagemaker_runtime or not SAGEMAKER_ENDPOINT_NAME:
            raise ValueError(
                "SageMaker service is not configured. Check environment variables and client initialization."
            )

        # The payload format depends on the model's container.
        # For Hugging Face TGI containers, it's typically a JSON object like this.
        payload = {
            "inputs": prompt,
            "parameters": {
                "max_new_tokens": 256,
                "do_sample": True,
                "top_p": 0.9,
                "temperature": 0.7,
            },
        }

        try:
            # Invoke the endpoint
            response = sagemaker_runtime.invoke_endpoint(
                EndpointName=SAGEMAKER_ENDPOINT_NAME,
                ContentType="application/json",
                Body=json.dumps(payload),
            )

            # Decode the response
            response_body = json.loads(response["Body"].read().decode())

            # The actual generated text is often in a specific key.
            # For TGI, it's typically in a list under the "generated_text" key.
            generated_text = response_body[0].get("generated_text", "")

            return generated_text.strip()

        except ClientError as e:
            # Handle specific Boto3 errors
            print(
                f"SageMaker ClientError: Failed to invoke endpoint {SAGEMAKER_ENDPOINT_NAME}. Error: {e}"
            )
            raise Exception("Failed to get a response from the model.") from e
        except Exception as e:
            # Handle other potential errors (e.g., JSON decoding)
            print(f"An unexpected error occurred while calling SageMaker: {e}")
            raise
